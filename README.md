# Regressão Linear Simples com Backpropagation

Este projeto demonstra a implementação de um modelo de rede neural simples usando o algoritmo de backpropagation para treinamento, explorando conceitos fundamentais de redes neurais.

## Descrição

O objetivo deste projeto é fornecer um exemplo prático de como construir e treinar um modelo de rede neural do zero, aplicando conceitos essenciais de redes neurais, como:

* **Neurônio Artificial (Perceptron Simples):** A função `forward` simula um neurônio básico.
* **Função de Perda (MSE):** A função `mse` calcula o erro, guiando o treinamento.
* **Backpropagation (Gradiente Descendente):** A função `backpropagation` ajusta os parâmetros.
* **Taxa de Aprendizado (lr):** Controla o tamanho dos ajustes durante o treinamento.
* **Treinamento Iterativo (Épocas):** O modelo é ajustado repetidamente para melhorar.

Este projeto inclui:

* Geração de dados de treinamento simulados.
* Implementação das funções de forward e backpropagation.
* Cálculo do erro quadrático médio (MSE) e do coeficiente de determinação (R²).
* Visualização dos dados e da linha de regressão ajustada.

## Como Usar

1.  **Clone o repositório:**

  

2.  **Execute o notebook Jupyter:**

    ```

3.  **Explore o código:**

    O notebook contém explicações passo a passo de cada parte do código, permitindo que você entenda como o modelo funciona e como os conceitos de redes neurais são aplicados.

## Requisitos

* Python 3.x
* NumPy
* Matplotlib

## Contribuição

Contribuições são bem-vindas! Se você encontrar algum problema ou tiver sugestões de melhorias, sinta-se à vontade para abrir uma issue ou enviar um pull request.



## Autor

Daniela Schuck


## Exemplo de uso

